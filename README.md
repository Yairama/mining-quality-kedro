# Mining Process Quality Prediction with Kedro

## ğŸ“Œ Overview
This project implements an **end-to-end, reproducible Machine Learning pipeline** to predict **silica concentration in a mining flotation process**, using **Kedro** as the orchestration framework.

The solution is based on the Kaggle dataset **â€œQuality Prediction in a Mining Processâ€** and refactors a traditional notebook-based approach into a **production-grade data pipeline**, including:
- Data ingestion and cleaning
- Time-based resampling
- Temporal train/test split
- XGBoost regression model
- Model evaluation
- SHAP explainability

The goal is not only prediction accuracy, but **traceability, reproducibility, and interpretability**, following industry best practices.

---

## ğŸ­ Business Context
In mineral processing plants, **silica concentration in the concentrate** is a critical quality indicator:
- High silica reduces concentrate quality
- Impacts downstream processing and costs
- Requires continuous monitoring and control

This project demonstrates how historical sensor data can be leveraged to **predict quality deviations** and **understand which process variables drive them**.

---

## ğŸ“Š Dataset
- Source: Kaggle â€“ *Quality Prediction in a Mining Process*
- Sampling rate: ~20 seconds
- Size: ~737,000 rows
- Features: process sensors (flows, pressures, reagents, air flow, etc.)
- Target variable: % Silica Concentrate


Raw data is **not stored in the repository** to keep it lightweight and reproducible.

---

## ğŸ§± Project Architecture (Kedro)

The project follows Kedroâ€™s standard structure:

```text
mining-quality-kedro/
â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ catalog.yml
â”‚   â”‚   â””â”€â”€ parameters.yml
â”œâ”€â”€ src/
â”‚   â””â”€â”€ mining_quality_kedro/
â”‚       â”œâ”€â”€ pipelines/
â”‚       â”‚   â””â”€â”€ mining_quality/
â”‚       â”‚       â”œâ”€â”€ nodes.py
â”‚       â”‚       â””â”€â”€ pipeline.py
â”‚       â””â”€â”€ pipeline_registry.py
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

suggested structure:
```text
mining-quality-kedro/
â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ catalog.yml              # datasets base (raw, intermediate, features)
â”‚   â”‚   â”œâ”€â”€ parameters.yml           # parÃ¡metros globales
â”‚   â”‚   â””â”€â”€ logging.yml              # config de logging
â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”œâ”€â”€ catalog.yml              # overrides locales
â”‚   â”‚   â”œâ”€â”€ parameters.yml
â”‚   â”‚   â””â”€â”€ credentials.yml          # NO versionar
â”‚   â””â”€â”€ README.md                    # cÃ³mo funciona la config
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01_raw/                      # datos crudos (sensores, laboratorio, etc.)
â”‚   â”œâ”€â”€ 02_intermediate/             # datos limpios parciales
â”‚   â”œâ”€â”€ 03_primary/                  # datasets listos para anÃ¡lisis
â”‚   â”œâ”€â”€ 04_feature/                  # features calculadas
â”‚   â”œâ”€â”€ 05_model_input/
â”‚   â”œâ”€â”€ 06_models/
â”‚   â””â”€â”€ 07_model_output/
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ source/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb            # EDA sin romper el pipeline
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ mining_quality_kedro/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ settings.py              # hooks, context, config
â”‚       â”‚
â”‚       â”œâ”€â”€ pipelines/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ data_pre_processing/
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚   â”œâ”€â”€ nodes.py          # limpieza, validaciones, imputaciones
â”‚       â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ quality_metrics/
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚   â”œâ”€â”€ nodes.py          # mÃ©tricas de calidad (outliers, drift, etc.)
â”‚       â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ reporting/
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â”œâ”€â”€ nodes.py          # reportes, KPIs
â”‚       â”‚       â””â”€â”€ pipeline.py
â”‚       â”‚
â”‚       â”œâ”€â”€ pipeline_registry.py     # registra y conecta pipelines
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ validators.py        # reglas de calidad
â”‚           â””â”€â”€ constants.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â””â”€â”€ test_data_pre_processing.py
â”‚   â””â”€â”€ test_run.py
â”‚
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## Pipeline Description

### 1. Data Cleaning
- Datetime parsing
- Conversion of decimal-comma values (e.g. `55,3 â†’ 55.3`)
- Duplicate and invalid row removal

### 2. Time Resampling
- Sensor data resampled to **hourly averages**
- Noise reduction and operational alignment

### 3. Temporal Train/Test Split
- Split performed strictly by time
- No shuffling, preserving real forecasting conditions

### 4. Model Training
- XGBoost Regressor
- Robust to non-linear relationships and sensor noise

### 5. Model Evaluation
- RMSE
- MAE
- RÂ² score

### 6. Explainability
- SHAP (SHapley Additive exPlanations)
- Global feature importance visualization
- Interpretability suitable for process engineers

---

## Outputs
After executing the pipeline, the following artifacts are generated locally:
- Cleaned and resampled datasets (Parquet)
- Trained XGBoost model
- Evaluation metrics (`metrics.json`)
- SHAP summary plot (`shap_summary.png`)

These artifacts are excluded from version control.

---

## How to Run

### 1. Create and activate virtual environment
```bash
python -m venv .venv
.venv\Scripts\activate
```

### 2. Install dependencies
```bash
pip install kedro kedro-datasets pandas numpy scikit-learn xgboost shap pyarrow matplotlib
```

### 3. Run the pipeline
```bash
kedro run
```


### 4. Visualize pipeline DAG
```bash
kedro viz
```

## Reference

This project is inspired by a Kaggle solution using XGBoost and SHAP, re-engineered here into a modular, maintainable and reproducible ML pipeline.

## Future Improvements

- MLflow experiment tracking
- Hyperparameter optimization
- Feature selection pipelines
- Real-time inference integration
- Deployment-ready packaging
